{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "explicit-water",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from netrc import netrc\n",
    "from subprocess import Popen\n",
    "from getpass import getpass\n",
    "import urllib\n",
    "import urllib3\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "urllib3.disable_warnings()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "educated-sellers",
   "metadata": {},
   "source": [
    "# Set path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "consecutive-murder",
   "metadata": {},
   "outputs": [],
   "source": [
    "#set saveDir\n",
    "import os\n",
    "\n",
    "# Parent Directory path\n",
    "parent_dir = os.getcwd()+r'\\foodsecurity_census\\HPS_data'\n",
    "  \n",
    "# Directory\n",
    "foodsecurity = \"Foodsecurity\"\n",
    "employment = \"Employment\"\n",
    "education = \"Education\"\n",
    "\n",
    "# Paths\n",
    "foodsecurity_path = os.path.join(parent_dir, foodsecurity)\n",
    "employment_path = os.path.join(parent_dir, employment)\n",
    "education_path = os.path.join(parent_dir, education)\n",
    "\n",
    "path = [foodsecurity_path, employment_path, education_path]\n",
    "\n",
    "for p in path:\n",
    "    if os.path.exists(p.strip()):\n",
    "        pass\n",
    "    else:\n",
    "        os.mkdir(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "considered-boxing",
   "metadata": {},
   "source": [
    "# 1. Download HPS data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "beginning-bridge",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extracturl(url):\n",
    "    # Retreive links in the URL path\n",
    "    urlpath = urllib.request.urlopen(url)\n",
    "    html_doc = urlpath.read().decode('utf-8')\n",
    "    \n",
    "    # BeautifulSoup object\n",
    "    soup = BeautifulSoup(html_doc, 'html.parser')\n",
    "    \n",
    "    # Make a list of hyerlinks\n",
    "    links = []\n",
    "    for link in soup.find_all('a'):\n",
    "        links.append(link.get('href'))\n",
    "    a=[]\n",
    "    for i in links:\n",
    "        if i != None :\n",
    "            a.append(i)\n",
    "    # Remove the parent link        \n",
    "    a.pop(0)     \n",
    "    return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "applicable-travel",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['https://www.census.gov//data/tables/2021/demo/hhp/hhp28.html',\n",
       " 'https://www.census.gov//data/tables/2021/demo/hhp/hhp27.html',\n",
       " 'https://www.census.gov//data/tables/2021/demo/hhp/hhp26.html',\n",
       " 'https://www.census.gov//data/tables/2021/demo/hhp/hhp25.html',\n",
       " 'https://www.census.gov//data/tables/2021/demo/hhp/hhp24.html',\n",
       " 'https://www.census.gov//data/tables/2021/demo/hhp/hhp23.html',\n",
       " 'https://www.census.gov//data/tables/2021/demo/hhp/hhp22.html',\n",
       " 'https://www.census.gov//data/tables/2020/demo/hhp/hhp21.html',\n",
       " 'https://www.census.gov//data/tables/2020/demo/hhp/hhp20.html',\n",
       " 'https://www.census.gov//data/tables/2020/demo/hhp/hhp19.html',\n",
       " 'https://www.census.gov//data/tables/2020/demo/hhp/hhp18.html',\n",
       " 'https://www.census.gov//data/tables/2020/demo/hhp/hhp17.html',\n",
       " 'https://www.census.gov//data/tables/2020/demo/hhp/hhp16.html',\n",
       " 'https://www.census.gov//data/tables/2020/demo/hhp/hhp15.html',\n",
       " 'https://www.census.gov//data/tables/2020/demo/hhp/hhp14.html',\n",
       " 'https://www.census.gov//data/tables/2020/demo/hhp/hhp13.html',\n",
       " 'https://www.census.gov//data/tables/2020/demo/hhp/hhp12.html',\n",
       " 'https://www.census.gov//data/tables/2020/demo/hhp/hhp11.html',\n",
       " 'https://www.census.gov//data/tables/2020/demo/hhp/hhp10.html',\n",
       " 'https://www.census.gov//data/tables/2020/demo/hhp/hhp9.html',\n",
       " 'https://www.census.gov//data/tables/2020/demo/hhp/hhp8.html',\n",
       " 'https://www.census.gov//data/tables/2020/demo/hhp/hhp7.html',\n",
       " 'https://www.census.gov//data/tables/2020/demo/hhp/hhp6.html',\n",
       " 'https://www.census.gov//data/tables/2020/demo/hhp/hhp5.html',\n",
       " 'https://www.census.gov//data/tables/2020/demo/hhp/hhp4.html',\n",
       " 'https://www.census.gov//data/tables/2020/demo/hhp/hhp3.html',\n",
       " 'https://www.census.gov//data/tables/2020/demo/hhp/hhp2.html',\n",
       " 'https://www.census.gov//data/tables/2020/demo/hhp/hhp1.html']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sub directories\n",
    "url = 'https://www.census.gov/programs-surveys/household-pulse-survey/data.html'\n",
    "url2 = 'https://www.census.gov/'\n",
    "url_sub = extracturl(url)\n",
    "url_sub = [x for x in url_sub if 'hhp' in x]        \n",
    "\n",
    "# URL format\n",
    "url_sub = [url2+t for t in url_sub]\n",
    "print(len(url_sub))\n",
    "url_sub"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "genetic-azerbaijan",
   "metadata": {},
   "source": [
    "## 1-1. Download Food security"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "matched-findings",
   "metadata": {},
   "outputs": [],
   "source": [
    "foodfile=[]\n",
    "\n",
    "for i in url_sub:\n",
    "    interest = [t for t in extracturl(i) if ('food2' in t) & ('food2a' not in t) & ('_se' not in t)]\n",
    "    foodfile.append('http:'+interest[0])\n",
    "    saveName=[]\n",
    "    for j in foodfile:\n",
    "        saveName.append(os.path.join(foodsecurity_path, j.split('/')[-1].strip()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "preliminary-picking",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded file: C:\\Users\\ck24\\ACE_592\\covid-19-data\\foodsecurity_census\\HPS_data\\Foodsecurity\\food2_week28.xlsx\n",
      "Downloaded file: C:\\Users\\ck24\\ACE_592\\covid-19-data\\foodsecurity_census\\HPS_data\\Foodsecurity\\food2_week27.xlsx\n",
      "Downloaded file: C:\\Users\\ck24\\ACE_592\\covid-19-data\\foodsecurity_census\\HPS_data\\Foodsecurity\\food2_week26.xlsx\n",
      "Downloaded file: C:\\Users\\ck24\\ACE_592\\covid-19-data\\foodsecurity_census\\HPS_data\\Foodsecurity\\food2_week25.xlsx\n",
      "Downloaded file: C:\\Users\\ck24\\ACE_592\\covid-19-data\\foodsecurity_census\\HPS_data\\Foodsecurity\\food2_week24.xlsx\n",
      "Downloaded file: C:\\Users\\ck24\\ACE_592\\covid-19-data\\foodsecurity_census\\HPS_data\\Foodsecurity\\food2_week23.xlsx\n",
      "Downloaded file: C:\\Users\\ck24\\ACE_592\\covid-19-data\\foodsecurity_census\\HPS_data\\Foodsecurity\\food2_week22.xlsx\n",
      "Downloaded file: C:\\Users\\ck24\\ACE_592\\covid-19-data\\foodsecurity_census\\HPS_data\\Foodsecurity\\food2b_week21.xlsx\n",
      "Downloaded file: C:\\Users\\ck24\\ACE_592\\covid-19-data\\foodsecurity_census\\HPS_data\\Foodsecurity\\food2b_week20.xlsx\n",
      "Downloaded file: C:\\Users\\ck24\\ACE_592\\covid-19-data\\foodsecurity_census\\HPS_data\\Foodsecurity\\food2b_week19.xlsx\n",
      "Downloaded file: C:\\Users\\ck24\\ACE_592\\covid-19-data\\foodsecurity_census\\HPS_data\\Foodsecurity\\food2b_week18.xlsx\n",
      "Downloaded file: C:\\Users\\ck24\\ACE_592\\covid-19-data\\foodsecurity_census\\HPS_data\\Foodsecurity\\food2b_week17.xlsx\n",
      "Downloaded file: C:\\Users\\ck24\\ACE_592\\covid-19-data\\foodsecurity_census\\HPS_data\\Foodsecurity\\food2b_week16.xlsx\n",
      "Downloaded file: C:\\Users\\ck24\\ACE_592\\covid-19-data\\foodsecurity_census\\HPS_data\\Foodsecurity\\food2b_week15.xlsx\n",
      "Downloaded file: C:\\Users\\ck24\\ACE_592\\covid-19-data\\foodsecurity_census\\HPS_data\\Foodsecurity\\food2b_week14.xlsx\n",
      "Downloaded file: C:\\Users\\ck24\\ACE_592\\covid-19-data\\foodsecurity_census\\HPS_data\\Foodsecurity\\food2b_week13.xlsx\n",
      "Downloaded file: C:\\Users\\ck24\\ACE_592\\covid-19-data\\foodsecurity_census\\HPS_data\\Foodsecurity\\food2b_week12.xlsx\n",
      "Downloaded file: C:\\Users\\ck24\\ACE_592\\covid-19-data\\foodsecurity_census\\HPS_data\\Foodsecurity\\food2b_week11.xlsx\n",
      "Downloaded file: C:\\Users\\ck24\\ACE_592\\covid-19-data\\foodsecurity_census\\HPS_data\\Foodsecurity\\food2b_week10.xlsx\n",
      "Downloaded file: C:\\Users\\ck24\\ACE_592\\covid-19-data\\foodsecurity_census\\HPS_data\\Foodsecurity\\food2b_week9.xlsx\n",
      "Downloaded file: C:\\Users\\ck24\\ACE_592\\covid-19-data\\foodsecurity_census\\HPS_data\\Foodsecurity\\food2b_week8.xlsx\n",
      "Downloaded file: C:\\Users\\ck24\\ACE_592\\covid-19-data\\foodsecurity_census\\HPS_data\\Foodsecurity\\food2b_week7.xlsx\n",
      "Downloaded file: C:\\Users\\ck24\\ACE_592\\covid-19-data\\foodsecurity_census\\HPS_data\\Foodsecurity\\food2b_week6.xlsx\n",
      "Downloaded file: C:\\Users\\ck24\\ACE_592\\covid-19-data\\foodsecurity_census\\HPS_data\\Foodsecurity\\food2b_week5.xlsx\n",
      "Downloaded file: C:\\Users\\ck24\\ACE_592\\covid-19-data\\foodsecurity_census\\HPS_data\\Foodsecurity\\food2b_week4.xlsx\n",
      "Downloaded file: C:\\Users\\ck24\\ACE_592\\covid-19-data\\foodsecurity_census\\HPS_data\\Foodsecurity\\food2b_week3.xlsx\n",
      "Downloaded file: C:\\Users\\ck24\\ACE_592\\covid-19-data\\foodsecurity_census\\HPS_data\\Foodsecurity\\food2b_week2.xlsx\n",
      "Downloaded file: C:\\Users\\ck24\\ACE_592\\covid-19-data\\foodsecurity_census\\HPS_data\\Foodsecurity\\food2b_week1.xlsx\n"
     ]
    }
   ],
   "source": [
    "# This cell will download every files to 'saveDir'\n",
    "\n",
    "for i,f in enumerate(foodfile):\n",
    "    with requests.get(f.strip()) as response:\n",
    "        if response.status_code != 200:\n",
    "            print(\"cannot downloaded\")\n",
    "        else:\n",
    "            response.raw.decode_content = True\n",
    "            content = response.raw\n",
    "            with open(saveName[i], 'wb') as d:\n",
    "                    d.write(response.content)\n",
    "            print('Downloaded file: {}'.format(saveName[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "entitled-cambridge",
   "metadata": {},
   "source": [
    "## 1-2. Download Employment data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "encouraging-conclusion",
   "metadata": {},
   "outputs": [],
   "source": [
    "emp_file=[]\n",
    "\n",
    "for i in url_sub[:28]:\n",
    "    employ = [t for t in extracturl(i) if ('employ1' in t) & ('_se_' not in t)]\n",
    "    emp_file.append('http:'+employ[0])\n",
    "    saveName=[]\n",
    "    for j in emp_file:\n",
    "        saveName.append(os.path.join(employment_path, j.split('/')[-1].strip()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "statewide-examination",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded file: C:\\Users\\ck24\\ACE_592\\covid-19-data\\foodsecurity_census\\HPS_data\\Employment\\employ1_week28.xlsx\n",
      "Downloaded file: C:\\Users\\ck24\\ACE_592\\covid-19-data\\foodsecurity_census\\HPS_data\\Employment\\employ1_week27.xlsx\n",
      "Downloaded file: C:\\Users\\ck24\\ACE_592\\covid-19-data\\foodsecurity_census\\HPS_data\\Employment\\employ1_week26.xlsx\n",
      "Downloaded file: C:\\Users\\ck24\\ACE_592\\covid-19-data\\foodsecurity_census\\HPS_data\\Employment\\employ1_week25.xlsx\n",
      "Downloaded file: C:\\Users\\ck24\\ACE_592\\covid-19-data\\foodsecurity_census\\HPS_data\\Employment\\employ1_week24.xlsx\n",
      "Downloaded file: C:\\Users\\ck24\\ACE_592\\covid-19-data\\foodsecurity_census\\HPS_data\\Employment\\employ1_week23.xlsx\n",
      "Downloaded file: C:\\Users\\ck24\\ACE_592\\covid-19-data\\foodsecurity_census\\HPS_data\\Employment\\employ1_week22.xlsx\n",
      "Downloaded file: C:\\Users\\ck24\\ACE_592\\covid-19-data\\foodsecurity_census\\HPS_data\\Employment\\employ1_week21.xlsx\n",
      "Downloaded file: C:\\Users\\ck24\\ACE_592\\covid-19-data\\foodsecurity_census\\HPS_data\\Employment\\employ1_week20.xlsx\n",
      "Downloaded file: C:\\Users\\ck24\\ACE_592\\covid-19-data\\foodsecurity_census\\HPS_data\\Employment\\employ1_week19.xlsx\n",
      "Downloaded file: C:\\Users\\ck24\\ACE_592\\covid-19-data\\foodsecurity_census\\HPS_data\\Employment\\employ1_week18.xlsx\n",
      "Downloaded file: C:\\Users\\ck24\\ACE_592\\covid-19-data\\foodsecurity_census\\HPS_data\\Employment\\employ1_week17.xlsx\n",
      "Downloaded file: C:\\Users\\ck24\\ACE_592\\covid-19-data\\foodsecurity_census\\HPS_data\\Employment\\employ1_week16.xlsx\n",
      "Downloaded file: C:\\Users\\ck24\\ACE_592\\covid-19-data\\foodsecurity_census\\HPS_data\\Employment\\employ1_week15.xlsx\n",
      "Downloaded file: C:\\Users\\ck24\\ACE_592\\covid-19-data\\foodsecurity_census\\HPS_data\\Employment\\employ1_week14.xlsx\n",
      "Downloaded file: C:\\Users\\ck24\\ACE_592\\covid-19-data\\foodsecurity_census\\HPS_data\\Employment\\employ1_week13.xlsx\n",
      "Downloaded file: C:\\Users\\ck24\\ACE_592\\covid-19-data\\foodsecurity_census\\HPS_data\\Employment\\employ1_week12.xlsx\n",
      "Downloaded file: C:\\Users\\ck24\\ACE_592\\covid-19-data\\foodsecurity_census\\HPS_data\\Employment\\employ1_week11.xlsx\n",
      "Downloaded file: C:\\Users\\ck24\\ACE_592\\covid-19-data\\foodsecurity_census\\HPS_data\\Employment\\employ1_week10.xlsx\n",
      "Downloaded file: C:\\Users\\ck24\\ACE_592\\covid-19-data\\foodsecurity_census\\HPS_data\\Employment\\employ1_week9.xlsx\n",
      "Downloaded file: C:\\Users\\ck24\\ACE_592\\covid-19-data\\foodsecurity_census\\HPS_data\\Employment\\employ1_week8.xlsx\n",
      "Downloaded file: C:\\Users\\ck24\\ACE_592\\covid-19-data\\foodsecurity_census\\HPS_data\\Employment\\employ1_week7.xlsx\n",
      "Downloaded file: C:\\Users\\ck24\\ACE_592\\covid-19-data\\foodsecurity_census\\HPS_data\\Employment\\employ1_week6.xlsx\n",
      "Downloaded file: C:\\Users\\ck24\\ACE_592\\covid-19-data\\foodsecurity_census\\HPS_data\\Employment\\employ1_week5.xlsx\n",
      "Downloaded file: C:\\Users\\ck24\\ACE_592\\covid-19-data\\foodsecurity_census\\HPS_data\\Employment\\employ1_week4.xlsx\n",
      "Downloaded file: C:\\Users\\ck24\\ACE_592\\covid-19-data\\foodsecurity_census\\HPS_data\\Employment\\employ1_week3.xlsx\n",
      "Downloaded file: C:\\Users\\ck24\\ACE_592\\covid-19-data\\foodsecurity_census\\HPS_data\\Employment\\employ1_week2.xlsx\n",
      "Downloaded file: C:\\Users\\ck24\\ACE_592\\covid-19-data\\foodsecurity_census\\HPS_data\\Employment\\employ1_week1.xlsx\n"
     ]
    }
   ],
   "source": [
    "# This cell will download every files to 'saveDir'\n",
    "\n",
    "for i,f in enumerate(emp_file):\n",
    "    with requests.get(f.strip()) as response:\n",
    "        if response.status_code != 200:\n",
    "            print(\"cannot download\")\n",
    "        else:\n",
    "            response.raw.decode_content = True\n",
    "            content = response.raw\n",
    "            with open(saveName[i], 'wb') as d:\n",
    "                    d.write(response.content)\n",
    "            print('Downloaded file: {}'.format(saveName[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "grave-fossil",
   "metadata": {},
   "source": [
    "# Cleaning FS CPS data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "coordinated-services",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import openpyxl\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "novel-lingerie",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Food data list\n",
    "food_list = glob.glob(foodsecurity_path+r'\\*.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ecological-synthetic",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['US',\n",
       " 'AL',\n",
       " 'AK',\n",
       " 'AZ',\n",
       " 'AR',\n",
       " 'CA',\n",
       " 'CO',\n",
       " 'CT',\n",
       " 'DE',\n",
       " 'DC',\n",
       " 'FL',\n",
       " 'GA',\n",
       " 'HI',\n",
       " 'ID',\n",
       " 'IL',\n",
       " 'IN',\n",
       " 'IA',\n",
       " 'KS',\n",
       " 'KY',\n",
       " 'LA',\n",
       " 'ME',\n",
       " 'MD',\n",
       " 'MA',\n",
       " 'MI',\n",
       " 'MN',\n",
       " 'MS',\n",
       " 'MO',\n",
       " 'MT',\n",
       " 'NE',\n",
       " 'NV',\n",
       " 'NH',\n",
       " 'NJ',\n",
       " 'NM',\n",
       " 'NY',\n",
       " 'NC',\n",
       " 'ND',\n",
       " 'OH',\n",
       " 'OK',\n",
       " 'OR',\n",
       " 'PA',\n",
       " 'RI',\n",
       " 'SC',\n",
       " 'SD',\n",
       " 'TN',\n",
       " 'TX',\n",
       " 'UT',\n",
       " 'VT',\n",
       " 'VA',\n",
       " 'WA',\n",
       " 'WV',\n",
       " 'WI',\n",
       " 'WY']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#extract state name\n",
    "wb = openpyxl.load_workbook(food_list[0])\n",
    "state_code=wb.sheetnames[0:52]\n",
    "print(len(state_code))\n",
    "state_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "particular-spectacular",
   "metadata": {},
   "outputs": [],
   "source": [
    "## subset data file by excel structure\n",
    "#from week 1 to 12\n",
    "foodlist_type1 = [s for s in food_list if int(s[-11:-5][4:].replace('k','')) in np.arange(1,13,1).tolist()]\n",
    "#from week 13 to 28\n",
    "foodlist_type2 = [s for s in food_list if int(s[-11:-5][4:].replace('k','')) in np.arange(13,29,1).tolist()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "german-dollar",
   "metadata": {},
   "outputs": [],
   "source": [
    "extraction=[]\n",
    "final=[]\n",
    "\n",
    "#type 1 extraction\n",
    "for sub_food in food_list[0:2]:\n",
    "    for state in state_code:\n",
    "        if sub_food in foodlist_type1: \n",
    "            df = pd.read_excel(sub_food,\n",
    "                  sheet_name = state,\n",
    "                  usecols = \"B:G\",\n",
    "                  engine='openpyxl',\n",
    "                  header=4)[:2].drop(0).rename(columns={'Unnamed: 1':\"total\"})\n",
    "        else: \n",
    "            df = pd.read_excel(sub_food,\n",
    "                  sheet_name = state,\n",
    "                  usecols = \"B:G\",\n",
    "                  engine='openpyxl',\n",
    "                  header=5)[:2].drop(0).rename(columns={'Unnamed: 1':\"total\"})\n",
    "        week = sub_food[-11:-5].replace('_','')\n",
    "        if len(week) == 5:\n",
    "            week = week[:4]+'0'+week[-1]\n",
    "        normalize = df/int(df.total.values)\n",
    "        fs=normalize.iloc[:,3:5].sum(axis=1).values\n",
    "        \n",
    "        df_final=pd.DataFrame(columns=['FI_'+week,'state','week']) \n",
    "        df_final['FI_'+week]=fs\n",
    "        df_final['state']=[state]\n",
    "        df_final['week']=[week]\n",
    "        extraction.append(df_final)\n",
    "final.append(extraction)\n",
    "#slice every 52 items and bind them in a sublist\n",
    "final = [pd.concat(final[0][x:x+52]) for x in range(0, len(final[0]),52)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "musical-crest",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[   FI_week01 state    week\n",
       " 0   0.096599    US  week01\n",
       " 0   0.103156    AL  week01\n",
       " 0   0.073330    AK  week01\n",
       " 0   0.093579    AZ  week01\n",
       " 0   0.118458    AR  week01\n",
       " 0   0.096177    CA  week01\n",
       " 0   0.074884    CO  week01\n",
       " 0   0.087388    CT  week01\n",
       " 0   0.115265    DE  week01\n",
       " 0   0.126335    DC  week01\n",
       " 0   0.099144    FL  week01\n",
       " 0   0.112118    GA  week01\n",
       " 0   0.098722    HI  week01\n",
       " 0   0.077493    ID  week01\n",
       " 0   0.104585    IL  week01\n",
       " 0   0.093406    IN  week01\n",
       " 0   0.069391    IA  week01\n",
       " 0   0.067190    KS  week01\n",
       " 0   0.111423    KY  week01\n",
       " 0   0.157243    LA  week01\n",
       " 0   0.053891    ME  week01\n",
       " 0   0.104055    MD  week01\n",
       " 0   0.070244    MA  week01\n",
       " 0   0.092267    MI  week01\n",
       " 0   0.066061    MN  week01\n",
       " 0   0.120759    MS  week01\n",
       " 0   0.104865    MO  week01\n",
       " 0   0.068872    MT  week01\n",
       " 0   0.084632    NE  week01\n",
       " 0   0.102360    NV  week01\n",
       " 0   0.045847    NH  week01\n",
       " 0   0.116710    NJ  week01\n",
       " 0   0.095885    NM  week01\n",
       " 0   0.091248    NY  week01\n",
       " 0   0.076990    NC  week01\n",
       " 0   0.031577    ND  week01\n",
       " 0   0.109297    OH  week01\n",
       " 0   0.083620    OK  week01\n",
       " 0   0.067974    OR  week01\n",
       " 0   0.102359    PA  week01\n",
       " 0   0.069123    RI  week01\n",
       " 0   0.113994    SC  week01\n",
       " 0   0.049846    SD  week01\n",
       " 0   0.115649    TN  week01\n",
       " 0   0.120900    TX  week01\n",
       " 0   0.060671    UT  week01\n",
       " 0   0.054568    VT  week01\n",
       " 0   0.083335    VA  week01\n",
       " 0   0.067005    WA  week01\n",
       " 0   0.075293    WV  week01\n",
       " 0   0.075416    WI  week01\n",
       " 0   0.054557    WY  week01,\n",
       "    FI_week10 state    week\n",
       " 0   0.105648    US  week10\n",
       " 0   0.127868    AL  week10\n",
       " 0   0.060896    AK  week10\n",
       " 0   0.087262    AZ  week10\n",
       " 0   0.133247    AR  week10\n",
       " 0   0.116376    CA  week10\n",
       " 0   0.090617    CO  week10\n",
       " 0   0.092051    CT  week10\n",
       " 0   0.057555    DE  week10\n",
       " 0   0.141194    DC  week10\n",
       " 0   0.110041    FL  week10\n",
       " 0   0.129651    GA  week10\n",
       " 0   0.097364    HI  week10\n",
       " 0   0.079648    ID  week10\n",
       " 0   0.118253    IL  week10\n",
       " 0   0.089928    IN  week10\n",
       " 0   0.069987    IA  week10\n",
       " 0   0.068402    KS  week10\n",
       " 0   0.140672    KY  week10\n",
       " 0   0.171681    LA  week10\n",
       " 0   0.079784    ME  week10\n",
       " 0   0.116899    MD  week10\n",
       " 0   0.053712    MA  week10\n",
       " 0   0.059372    MI  week10\n",
       " 0   0.073921    MN  week10\n",
       " 0   0.105295    MS  week10\n",
       " 0   0.078257    MO  week10\n",
       " 0   0.114133    MT  week10\n",
       " 0   0.082335    NE  week10\n",
       " 0   0.174116    NV  week10\n",
       " 0   0.061703    NH  week10\n",
       " 0   0.082030    NJ  week10\n",
       " 0   0.128260    NM  week10\n",
       " 0   0.096322    NY  week10\n",
       " 0   0.079455    NC  week10\n",
       " 0   0.060578    ND  week10\n",
       " 0   0.167704    OH  week10\n",
       " 0   0.127819    OK  week10\n",
       " 0   0.095320    OR  week10\n",
       " 0   0.087384    PA  week10\n",
       " 0   0.098376    RI  week10\n",
       " 0   0.117102    SC  week10\n",
       " 0   0.111440    SD  week10\n",
       " 0   0.121957    TN  week10\n",
       " 0   0.134614    TX  week10\n",
       " 0   0.098456    UT  week10\n",
       " 0   0.080373    VT  week10\n",
       " 0   0.082103    VA  week10\n",
       " 0   0.072394    WA  week10\n",
       " 0   0.107286    WV  week10\n",
       " 0   0.068119    WI  week10\n",
       " 0   0.122081    WY  week10]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "usual-straight",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge data\n",
    "from functools import reduce\n",
    "fi_final_df=reduce(lambda x, y: pd.merge(x, y, on='state'), final)\n",
    "\n",
    "subset_week = [x for x in fi_final_df if not x.startswith('week')]\n",
    "fi_final_df[subset_week]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "incorporated-democrat",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extraction(data_list, type1, usecols, header1, header2, range1, range2, colname):\n",
    "    for sub in data_list:\n",
    "        for state in state_code:\n",
    "            if sub in type1: \n",
    "                df = pd.read_excel(sub,\n",
    "                      sheet_name = state,\n",
    "                      usecols = usecols,\n",
    "                      engine='openpyxl',\n",
    "                      header=header1)[:2].drop(0).rename(columns={'Unnamed: 1':\"total\"})\n",
    "            else : \n",
    "                df = pd.read_excel(sub,\n",
    "                      sheet_name = state,\n",
    "                      usecols = usecols,\n",
    "                      engine='openpyxl',\n",
    "                      header=header2)[:2].drop(0).rename(columns={'Unnamed: 1':\"total\"})\n",
    "\n",
    "            week = sub[-11:-5].replace('_','')\n",
    "            if len(week) == 5:\n",
    "                week = week[:4]+'0'+week[-1]\n",
    "\n",
    "            interest = df.iloc[:,range1:range2].sum(axis=1).values\n",
    "            ratio = interest/int(df['total'].values)\n",
    "\n",
    "            df_final = pd.DataFrame(columns=[colname+week,'state'])#,'week']) \n",
    "            df_final[colname+week]=ratio\n",
    "            df_final['state']=[state]\n",
    "            #df_final['week']=[week]\n",
    "            extract.append(df_final)\n",
    "    #final.append(extract)\n",
    "    #slice every 51 items and bind them in a sublist\n",
    "    #final = [pd.concat(final[0][x:x+51]) for x in range(0, len(final[0]),51)]\n",
    "    \n",
    "    #return final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "mineral-nelson",
   "metadata": {},
   "outputs": [],
   "source": [
    "extract=[]\n",
    "final=[]\n",
    "\n",
    "extraction(food_list[:2], foodlist_type1, \"B:G\", 4, 5, 3, 5, \"FI_\")\n",
    "final.append(extract)\n",
    "final = [pd.concat(final[0][x:x+51]) for x in range(0, len(final[0]),51)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "crazy-heather",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[   FI_week01 state\n",
       " 0   0.103156    AL\n",
       " 0   0.073330    AK\n",
       " 0   0.093579    AZ\n",
       " 0   0.118458    AR\n",
       " 0   0.096177    CA\n",
       " 0   0.074884    CO\n",
       " 0   0.087388    CT\n",
       " 0   0.115265    DE\n",
       " 0   0.126335    DC\n",
       " 0   0.099144    FL\n",
       " 0   0.112118    GA\n",
       " 0   0.098722    HI\n",
       " 0   0.077493    ID\n",
       " 0   0.104585    IL\n",
       " 0   0.093406    IN\n",
       " 0   0.069391    IA\n",
       " 0   0.067190    KS\n",
       " 0   0.111423    KY\n",
       " 0   0.157243    LA\n",
       " 0   0.053891    ME\n",
       " 0   0.104055    MD\n",
       " 0   0.070244    MA\n",
       " 0   0.092267    MI\n",
       " 0   0.066061    MN\n",
       " 0   0.120759    MS\n",
       " 0   0.104865    MO\n",
       " 0   0.068872    MT\n",
       " 0   0.084632    NE\n",
       " 0   0.102360    NV\n",
       " 0   0.045847    NH\n",
       " 0   0.116710    NJ\n",
       " 0   0.095885    NM\n",
       " 0   0.091248    NY\n",
       " 0   0.076990    NC\n",
       " 0   0.031577    ND\n",
       " 0   0.109297    OH\n",
       " 0   0.083620    OK\n",
       " 0   0.067974    OR\n",
       " 0   0.102359    PA\n",
       " 0   0.069123    RI\n",
       " 0   0.113994    SC\n",
       " 0   0.049846    SD\n",
       " 0   0.115649    TN\n",
       " 0   0.120900    TX\n",
       " 0   0.060671    UT\n",
       " 0   0.054568    VT\n",
       " 0   0.083335    VA\n",
       " 0   0.067005    WA\n",
       " 0   0.075293    WV\n",
       " 0   0.075416    WI\n",
       " 0   0.054557    WY,\n",
       "    FI_week10 state\n",
       " 0   0.127868    AL\n",
       " 0   0.060896    AK\n",
       " 0   0.087262    AZ\n",
       " 0   0.133247    AR\n",
       " 0   0.116376    CA\n",
       " 0   0.090617    CO\n",
       " 0   0.092051    CT\n",
       " 0   0.057555    DE\n",
       " 0   0.141194    DC\n",
       " 0   0.110041    FL\n",
       " 0   0.129651    GA\n",
       " 0   0.097364    HI\n",
       " 0   0.079648    ID\n",
       " 0   0.118253    IL\n",
       " 0   0.089928    IN\n",
       " 0   0.069987    IA\n",
       " 0   0.068402    KS\n",
       " 0   0.140672    KY\n",
       " 0   0.171681    LA\n",
       " 0   0.079784    ME\n",
       " 0   0.116899    MD\n",
       " 0   0.053712    MA\n",
       " 0   0.059372    MI\n",
       " 0   0.073921    MN\n",
       " 0   0.105295    MS\n",
       " 0   0.078257    MO\n",
       " 0   0.114133    MT\n",
       " 0   0.082335    NE\n",
       " 0   0.174116    NV\n",
       " 0   0.061703    NH\n",
       " 0   0.082030    NJ\n",
       " 0   0.128260    NM\n",
       " 0   0.096322    NY\n",
       " 0   0.079455    NC\n",
       " 0   0.060578    ND\n",
       " 0   0.167704    OH\n",
       " 0   0.127819    OK\n",
       " 0   0.095320    OR\n",
       " 0   0.087384    PA\n",
       " 0   0.098376    RI\n",
       " 0   0.117102    SC\n",
       " 0   0.111440    SD\n",
       " 0   0.121957    TN\n",
       " 0   0.134614    TX\n",
       " 0   0.098456    UT\n",
       " 0   0.080373    VT\n",
       " 0   0.082103    VA\n",
       " 0   0.072394    WA\n",
       " 0   0.107286    WV\n",
       " 0   0.068119    WI\n",
       " 0   0.122081    WY]"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "several-tuning",
   "metadata": {},
   "outputs": [],
   "source": [
    "fi_final_df = final1+final2\n",
    "print(len(fi_final_df))\n",
    "fi_final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "narrative-refrigerator",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "seeing-revolution",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Merge district Tmax_mean\n",
    "final = final1+final2\n",
    "\n",
    "from functools import reduce\n",
    "fi_final_df=reduce(lambda x, y: pd.merge(x, y, on='state'), final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "crucial-modification",
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_week = [x for x in fi_final_df if not x.startswith('week')]\n",
    "fi_final_df[subset_week].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fallen-retention",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "assigned-photography",
   "metadata": {},
   "outputs": [],
   "source": [
    "extraction=[]\n",
    "\n",
    "for state in state_code:\n",
    "    df = pd.read_excel(food_list[0],\n",
    "                  sheet_name = state,\n",
    "                  usecols = \"B:G\",\n",
    "                  engine='openpyxl',\n",
    "                  header=4)[:2].drop(0).rename(columns={'Unnamed: 1':\"total\"})\n",
    "    week = food_list[0][-11:-5].replace('_','')\n",
    "    normalize = df/int(df.total.values)\n",
    "    fs=normalize.iloc[:,3:5].sum(axis=1).values\n",
    "    df_final=pd.DataFrame(columns=['FI_ratio','state','week']) \n",
    "    \n",
    "    df_final['FI_ratio']=fs\n",
    "    df_final['state']=[state]\n",
    "    df_final['week']=[week]\n",
    "    extraction.append(df_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "established-occasions",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\ck24\\\\ACE_592\\\\covid-19-data\\\\foodsecurity_census\\\\HPS_data\\\\food2b_week13.xlsx'"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "food_list[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "accurate-cowboy",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total</th>\n",
       "      <th>Enough of the types of food wanted</th>\n",
       "      <th>Enough food, but not always the types wanted</th>\n",
       "      <th>Sometimes not enough to eat</th>\n",
       "      <th>Often not enough to eat</th>\n",
       "      <th>Did not report</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3717378.0</td>\n",
       "      <td>1786559</td>\n",
       "      <td>950236</td>\n",
       "      <td>384442</td>\n",
       "      <td>64174</td>\n",
       "      <td>531968</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       total Enough of the types of food wanted  \\\n",
       "1  3717378.0                            1786559   \n",
       "\n",
       "  Enough food, but not always the types wanted Sometimes not enough to eat  \\\n",
       "1                                       950236                      384442   \n",
       "\n",
       "  Often not enough to eat Did not report  \n",
       "1                   64174         531968  "
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_excel(food_list[4],\n",
    "                  sheet_name = 'AL',\n",
    "                  usecols = \"B:G\",\n",
    "                  engine='openpyxl',\n",
    "                  header=5)[:2].drop(0).rename(columns={'Unnamed: 1':\"total\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lovely-beaver",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(food_list[0],\n",
    "                  sheet_name = state,\n",
    "                  usecols = \"B:G\",\n",
    "                  engine='openpyxl',\n",
    "                  header=4)[:2].drop(0).rename(columns={'Unnamed: 1':\"total\"})\n",
    "    week = food_list[0][-11:-5].replace('_','')\n",
    "    normalize = df/int(df.total.values)\n",
    "    fs=normalize.iloc[:,3:5].sum(axis=1).values\n",
    "    df_final=pd.DataFrame(columns=['FI_ratio','state','week']) \n",
    "    \n",
    "    df_final['FI_ratio']=fs\n",
    "    df_final['state']=[state]\n",
    "    df_final['week']=[week]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "abandoned-scanning",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/data/tables/2021/demo/hhp/hhp27.html']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[t for t in res if 'hhp27' in t]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "positive-preview",
   "metadata": {},
   "outputs": [],
   "source": [
    "for sub in url_sub:\n",
    "    if not os.path.exists(saveDir):\n",
    "        os.makedirs(saveDir)\n",
    "        \n",
    "    # extract only 2004 / 2009 / 2014\n",
    "    fn_tif = [t for t in extracturl(sub) if ('2004' in t) | ('2009' in t) |('2014' in t)]\n",
    "    # Continue if no tif file\n",
    "    if len(fn_tif) == 0: continue\n",
    "    file=[]\n",
    "    saveName=[]\n",
    "    for i in fn_tif:\n",
    "        file.append(sub + i)\n",
    "        for j in file:\n",
    "            saveName.append(os.path.join(saveDir, j.split('/')[-1].strip()))\n",
    "            saveName = list(dict.fromkeys(saveName))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "suited-catch",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded file: C:\\Users\\ck24\\ACE_592\\Pollution_Sp21\\Data\\temp_month\\CHIRTmax.2004.01.tif\n",
      "Downloaded file: C:\\Users\\ck24\\ACE_592\\Pollution_Sp21\\Data\\temp_month\\CHIRTmax.2004.02.tif\n",
      "Downloaded file: C:\\Users\\ck24\\ACE_592\\Pollution_Sp21\\Data\\temp_month\\CHIRTmax.2004.03.tif\n",
      "Downloaded file: C:\\Users\\ck24\\ACE_592\\Pollution_Sp21\\Data\\temp_month\\CHIRTmax.2004.04.tif\n",
      "Downloaded file: C:\\Users\\ck24\\ACE_592\\Pollution_Sp21\\Data\\temp_month\\CHIRTmax.2004.05.tif\n",
      "Downloaded file: C:\\Users\\ck24\\ACE_592\\Pollution_Sp21\\Data\\temp_month\\CHIRTmax.2004.06.tif\n",
      "Downloaded file: C:\\Users\\ck24\\ACE_592\\Pollution_Sp21\\Data\\temp_month\\CHIRTmax.2004.07.tif\n",
      "Downloaded file: C:\\Users\\ck24\\ACE_592\\Pollution_Sp21\\Data\\temp_month\\CHIRTmax.2004.08.tif\n",
      "Downloaded file: C:\\Users\\ck24\\ACE_592\\Pollution_Sp21\\Data\\temp_month\\CHIRTmax.2004.09.tif\n",
      "Downloaded file: C:\\Users\\ck24\\ACE_592\\Pollution_Sp21\\Data\\temp_month\\CHIRTmax.2004.10.tif\n",
      "Downloaded file: C:\\Users\\ck24\\ACE_592\\Pollution_Sp21\\Data\\temp_month\\CHIRTmax.2004.11.tif\n",
      "Downloaded file: C:\\Users\\ck24\\ACE_592\\Pollution_Sp21\\Data\\temp_month\\CHIRTmax.2004.12.tif\n",
      "Downloaded file: C:\\Users\\ck24\\ACE_592\\Pollution_Sp21\\Data\\temp_month\\CHIRTmax.2009.01.tif\n",
      "Downloaded file: C:\\Users\\ck24\\ACE_592\\Pollution_Sp21\\Data\\temp_month\\CHIRTmax.2009.02.tif\n",
      "Downloaded file: C:\\Users\\ck24\\ACE_592\\Pollution_Sp21\\Data\\temp_month\\CHIRTmax.2009.03.tif\n",
      "Downloaded file: C:\\Users\\ck24\\ACE_592\\Pollution_Sp21\\Data\\temp_month\\CHIRTmax.2009.04.tif\n",
      "Downloaded file: C:\\Users\\ck24\\ACE_592\\Pollution_Sp21\\Data\\temp_month\\CHIRTmax.2009.05.tif\n",
      "Downloaded file: C:\\Users\\ck24\\ACE_592\\Pollution_Sp21\\Data\\temp_month\\CHIRTmax.2009.06.tif\n",
      "Downloaded file: C:\\Users\\ck24\\ACE_592\\Pollution_Sp21\\Data\\temp_month\\CHIRTmax.2009.07.tif\n",
      "Downloaded file: C:\\Users\\ck24\\ACE_592\\Pollution_Sp21\\Data\\temp_month\\CHIRTmax.2009.08.tif\n",
      "Downloaded file: C:\\Users\\ck24\\ACE_592\\Pollution_Sp21\\Data\\temp_month\\CHIRTmax.2009.09.tif\n",
      "Downloaded file: C:\\Users\\ck24\\ACE_592\\Pollution_Sp21\\Data\\temp_month\\CHIRTmax.2009.10.tif\n",
      "Downloaded file: C:\\Users\\ck24\\ACE_592\\Pollution_Sp21\\Data\\temp_month\\CHIRTmax.2009.11.tif\n",
      "Downloaded file: C:\\Users\\ck24\\ACE_592\\Pollution_Sp21\\Data\\temp_month\\CHIRTmax.2009.12.tif\n",
      "Downloaded file: C:\\Users\\ck24\\ACE_592\\Pollution_Sp21\\Data\\temp_month\\CHIRTmax.2014.01.tif\n",
      "Downloaded file: C:\\Users\\ck24\\ACE_592\\Pollution_Sp21\\Data\\temp_month\\CHIRTmax.2014.02.tif\n",
      "Downloaded file: C:\\Users\\ck24\\ACE_592\\Pollution_Sp21\\Data\\temp_month\\CHIRTmax.2014.03.tif\n",
      "Downloaded file: C:\\Users\\ck24\\ACE_592\\Pollution_Sp21\\Data\\temp_month\\CHIRTmax.2014.04.tif\n",
      "Downloaded file: C:\\Users\\ck24\\ACE_592\\Pollution_Sp21\\Data\\temp_month\\CHIRTmax.2014.05.tif\n",
      "Downloaded file: C:\\Users\\ck24\\ACE_592\\Pollution_Sp21\\Data\\temp_month\\CHIRTmax.2014.06.tif\n",
      "Downloaded file: C:\\Users\\ck24\\ACE_592\\Pollution_Sp21\\Data\\temp_month\\CHIRTmax.2014.07.tif\n",
      "Downloaded file: C:\\Users\\ck24\\ACE_592\\Pollution_Sp21\\Data\\temp_month\\CHIRTmax.2014.08.tif\n",
      "Downloaded file: C:\\Users\\ck24\\ACE_592\\Pollution_Sp21\\Data\\temp_month\\CHIRTmax.2014.09.tif\n",
      "Downloaded file: C:\\Users\\ck24\\ACE_592\\Pollution_Sp21\\Data\\temp_month\\CHIRTmax.2014.10.tif\n",
      "Downloaded file: C:\\Users\\ck24\\ACE_592\\Pollution_Sp21\\Data\\temp_month\\CHIRTmax.2014.11.tif\n",
      "Downloaded file: C:\\Users\\ck24\\ACE_592\\Pollution_Sp21\\Data\\temp_month\\CHIRTmax.2014.12.tif\n"
     ]
    }
   ],
   "source": [
    "# This cell will download & save every files to 'saveDir'\n",
    "\n",
    "for i,f in enumerate(file):\n",
    "    with requests.get(f.strip()) as response:\n",
    "        if response.status_code != 200:\n",
    "            print(\"cannot downloaded\")\n",
    "        else:\n",
    "            response.raw.decode_content = True\n",
    "            content = response.raw\n",
    "            with open(saveName[i], 'wb') as d:\n",
    "                #if os.path.exists(saveName[i]):\n",
    "                #    pass\n",
    "                #else:\n",
    "                    d.write(response.content)\n",
    "            print('Downloaded file: {}'.format(saveName[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "generic-scott",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
